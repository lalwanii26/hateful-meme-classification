{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1186ccd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: torch in /opt/conda/lib/python3.9/site-packages (1.9.0+cu111)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.9/site-packages (from torch) (4.5.0)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: transformers in /home/musharma/.local/lib/python3.9/site-packages (4.30.1)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /home/musharma/.local/lib/python3.9/site-packages (from transformers) (0.13.3)\n",
      "Requirement already satisfied: filelock in /home/musharma/.local/lib/python3.9/site-packages (from transformers) (3.12.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.9/site-packages (from transformers) (1.22.4)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.9/site-packages (from transformers) (5.4.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.9/site-packages (from transformers) (2023.5.5)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /home/musharma/.local/lib/python3.9/site-packages (from transformers) (0.3.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /home/musharma/.local/lib/python3.9/site-packages (from transformers) (0.15.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.9/site-packages (from transformers) (21.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.9/site-packages (from transformers) (4.61.2)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.9/site-packages (from transformers) (2.26.0)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2021.7.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.5.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.9/site-packages (from packaging>=20.0->transformers) (2.4.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.9/site-packages (from requests->transformers) (3.1)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.9/site-packages (from requests->transformers) (2.0.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.9/site-packages (from requests->transformers) (1.26.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.9/site-packages (from requests->transformers) (2023.5.7)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: sentence-transformers in /home/musharma/.local/lib/python3.9/site-packages (2.2.2)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.6.0 in /home/musharma/.local/lib/python3.9/site-packages (from sentence-transformers) (4.30.1)\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.9/site-packages (from sentence-transformers) (0.24.2)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.9/site-packages (from sentence-transformers) (1.22.4)\n",
      "Requirement already satisfied: torch>=1.6.0 in /opt/conda/lib/python3.9/site-packages (from sentence-transformers) (1.9.0+cu111)\n",
      "Requirement already satisfied: torchvision in /opt/conda/lib/python3.9/site-packages (from sentence-transformers) (0.10.0+cu111)\n",
      "Requirement already satisfied: huggingface-hub>=0.4.0 in /home/musharma/.local/lib/python3.9/site-packages (from sentence-transformers) (0.15.1)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.9/site-packages (from sentence-transformers) (1.7.0)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.9/site-packages (from sentence-transformers) (4.61.2)\n",
      "Requirement already satisfied: sentencepiece in /home/musharma/.local/lib/python3.9/site-packages (from sentence-transformers) (0.1.99)\n",
      "Requirement already satisfied: nltk in /opt/conda/lib/python3.9/site-packages (from sentence-transformers) (3.8.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.9/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (5.4.1)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.9/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (2021.7.0)\n",
      "Requirement already satisfied: filelock in /home/musharma/.local/lib/python3.9/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (3.12.0)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.9/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (2.26.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.9/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (4.5.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.9/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (21.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.9/site-packages (from packaging>=20.9->huggingface-hub>=0.4.0->sentence-transformers) (2.4.7)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /home/musharma/.local/lib/python3.9/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.13.3)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /home/musharma/.local/lib/python3.9/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.3.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.9/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (2023.5.5)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.9/site-packages (from nltk->sentence-transformers) (8.0.1)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.9/site-packages (from nltk->sentence-transformers) (1.0.1)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.9/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2.0.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.9/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (3.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.9/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (1.26.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.9/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2023.5.7)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.9/site-packages (from scikit-learn->sentence-transformers) (2.2.0)\n",
      "Requirement already satisfied: pillow>=5.3.0 in /opt/conda/lib/python3.9/site-packages (from torchvision->sentence-transformers) (8.3.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch\n",
    "!pip install transformers\n",
    "!pip install sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2851ee37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>img</th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>42953</td>\n",
       "      <td>img/42953.png</td>\n",
       "      <td>0</td>\n",
       "      <td>its their character not their color that matters</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23058</td>\n",
       "      <td>img/23058.png</td>\n",
       "      <td>0</td>\n",
       "      <td>don't be afraid to love again everyone is not ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13894</td>\n",
       "      <td>img/13894.png</td>\n",
       "      <td>0</td>\n",
       "      <td>putting bows on your pet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>37408</td>\n",
       "      <td>img/37408.png</td>\n",
       "      <td>0</td>\n",
       "      <td>i love everything and everybody! except for sq...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>82403</td>\n",
       "      <td>img/82403.png</td>\n",
       "      <td>0</td>\n",
       "      <td>everybody loves chocolate chip cookies, even h...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id            img  label  \\\n",
       "0  42953  img/42953.png      0   \n",
       "1  23058  img/23058.png      0   \n",
       "2  13894  img/13894.png      0   \n",
       "3  37408  img/37408.png      0   \n",
       "4  82403  img/82403.png      0   \n",
       "\n",
       "                                                text  \n",
       "0   its their character not their color that matters  \n",
       "1  don't be afraid to love again everyone is not ...  \n",
       "2                           putting bows on your pet  \n",
       "3  i love everything and everybody! except for sq...  \n",
       "4  everybody loves chocolate chip cookies, even h...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# f = pd.read_json(file_path, lines=True)\n",
    "df_image_train = pd.read_json(\"data/train.jsonl\", lines=True)\n",
    "df_image_val = pd.read_json(\"data/dev.jsonl\", lines=True)\n",
    "df_image_test = pd.read_json(\"data/test.jsonl\", lines=True)\n",
    "df_image_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b68ba118",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: transformers in /home/musharma/.local/lib/python3.9/site-packages (4.30.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /home/musharma/.local/lib/python3.9/site-packages (from transformers) (0.15.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.9/site-packages (from transformers) (4.61.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.9/site-packages (from transformers) (2023.5.5)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /home/musharma/.local/lib/python3.9/site-packages (from transformers) (0.13.3)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /home/musharma/.local/lib/python3.9/site-packages (from transformers) (0.3.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.9/site-packages (from transformers) (21.0)\n",
      "Requirement already satisfied: filelock in /home/musharma/.local/lib/python3.9/site-packages (from transformers) (3.12.0)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.9/site-packages (from transformers) (2.26.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.9/site-packages (from transformers) (5.4.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.9/site-packages (from transformers) (1.22.4)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.5.0)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2021.7.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.9/site-packages (from packaging>=20.0->transformers) (2.4.7)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.9/site-packages (from requests->transformers) (2.0.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.9/site-packages (from requests->transformers) (3.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.9/site-packages (from requests->transformers) (2023.5.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.9/site-packages (from requests->transformers) (1.26.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2c204c3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      id            img  label  \\\n",
      "0  42953  img/42953.png      0   \n",
      "1  23058  img/23058.png      0   \n",
      "2  13894  img/13894.png      0   \n",
      "3  37408  img/37408.png      0   \n",
      "4  82403  img/82403.png      0   \n",
      "\n",
      "                                                text  \n",
      "0   its their character not their color that matters  \n",
      "1  don't be afraid to love again everyone is not ...  \n",
      "2                           putting bows on your pet  \n",
      "3  i love everything and everybody! except for sq...  \n",
      "4  everybody loves chocolate chip cookies, even h...  \n"
     ]
    }
   ],
   "source": [
    "print(df_image_train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac3c9491",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "/opt/conda/lib/python3.9/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss: 0.5849014520645142\n",
      "Epoch: 1, Loss: 0.6733682155609131\n",
      "Epoch: 2, Loss: 0.9221835732460022\n",
      "Epoch: 3, Loss: 0.4037746787071228\n",
      "Epoch: 4, Loss: 0.5543085932731628\n",
      "Epoch: 5, Loss: 0.8913806080818176\n",
      "Epoch: 6, Loss: 0.7937508821487427\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torchvision.models as models\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import os\n",
    "import torchvision.transforms as T\n",
    "\n",
    "# Transformers model for text\n",
    "text_model = AutoModel.from_pretrained(\"bert-base-uncased\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "# Torchvision model for images\n",
    "image_model = models.resnet101(pretrained=True)\n",
    "image_model = nn.Sequential(*list(image_model.children())[:-1])  # Remove the last FC layer\n",
    "\n",
    "\n",
    "def collate_fn(batch):\n",
    "    images, texts, labels = zip(*batch)\n",
    "\n",
    "    # Pad sequences\n",
    "    input_ids = pad_sequence([t['input_ids'] for t in texts])\n",
    "    attention_mask = pad_sequence([t['attention_mask'] for t in texts])\n",
    "\n",
    "    # Convert to tensors\n",
    "    input_ids = torch.as_tensor(input_ids, dtype=torch.long)\n",
    "    attention_mask = torch.as_tensor(attention_mask, dtype=torch.long)\n",
    "    labels = torch.as_tensor(labels, dtype=torch.long)\n",
    "\n",
    "    # Transpose image tensor (batch_size should be first)\n",
    "    images = torch.stack(images).transpose(0, 1)\n",
    "    \n",
    "    return images, {'input_ids': input_ids, 'attention_mask': attention_mask}, labels\n",
    "\n",
    "\n",
    "class HatefulMemesDataset(Dataset):\n",
    "    def __init__(self, json_file, img_dir, transforms=None):\n",
    "        self.data = pd.read_json(json_file, lines=True)\n",
    "        self.img_dir = img_dir\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_id = self.data.loc[idx, 'img']\n",
    "        img_path = os.path.join(self.img_dir, img_id)\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "\n",
    "        if self.transforms:\n",
    "            image = self.transforms(image)\n",
    "        \n",
    "        # Process text data\n",
    "        text = self.data.loc[idx, 'text']\n",
    "        text = tokenizer(text, return_tensors='pt', padding=\"max_length\", truncation=True, max_length=64)\n",
    "\n",
    "        label = self.data.loc[idx, 'label']\n",
    "\n",
    "        return image, text, label\n",
    "\n",
    "\n",
    "# Define your transforms\n",
    "transforms = T.Compose([\n",
    "    T.Resize((224, 224)),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),  # normalization settings for resnet models\n",
    "])\n",
    "\n",
    "# Initialize your dataset\n",
    "dataset = HatefulMemesDataset(json_file=\"data/train.jsonl\",\n",
    "                              img_dir=\"data\",\n",
    "                              transforms=transforms)\n",
    "\n",
    "# Create DataLoader\n",
    "dataloader = DataLoader(dataset, batch_size=8, shuffle=True, collate_fn=collate_fn)\n",
    "\n",
    "# # Define a simple model for classification\n",
    "class CombinedModel(nn.Module):\n",
    "    def __init__(self, text_model, image_model):\n",
    "        super(CombinedModel, self).__init__()\n",
    "        self.text_model = text_model\n",
    "        self.image_model = image_model\n",
    "        self.classifier = nn.Linear(text_model.config.hidden_size + 2048, 2)  # 2048 is the output size of resnet101\n",
    "\n",
    "    def forward(self, image, input_ids, attention_mask):\n",
    "        text_features = self.text_model(input_ids=input_ids, attention_mask=attention_mask).last_hidden_state[:, 0, :]\n",
    "        image_features = self.image_model(image).view(image.size(0), -1)\n",
    "        combined = torch.cat((text_features, image_features), dim=1)\n",
    "        logits = self.classifier(combined)\n",
    "        return logits\n",
    "\n",
    "\n",
    "# Create your model\n",
    "model = CombinedModel(text_model, image_model)\n",
    "\n",
    "# Move to GPU if available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "\n",
    "# Loss and Optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 10\n",
    "model.train()\n",
    "for epoch in range(num_epochs):\n",
    "    for images, texts, labels in dataloader:\n",
    "        # Move inputs and targets to the same device as the model\n",
    "        images = images.permute(1, 0, 2, 3)\n",
    "        images = images.to(device)\n",
    "        input_ids = texts['input_ids'].squeeze().to(device)\n",
    "#         print(\"text attention mask\", texts['attention_mask'])\n",
    "        attention_mask = texts['attention_mask'].squeeze().to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        logits = model(images, input_ids, attention_mask)\n",
    "\n",
    "        # Compute the loss\n",
    "        loss = criterion(logits, labels)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "    print(f\"Epoch: {epoch}, Loss: {loss.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e343691",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import AutoTokenizer, AutoModel\n",
    "# import torchvision.models as models\n",
    "# import torch\n",
    "# from torch import nn, optim\n",
    "# from torch.utils.data import Dataset, DataLoader\n",
    "# from torch.nn.utils.rnn import pad_sequence\n",
    "# from PIL import Image\n",
    "# import pandas as pd\n",
    "# import os\n",
    "# import torchvision.transforms as T\n",
    "\n",
    "# # Transformers model for text\n",
    "# text_model = AutoModel.from_pretrained(\"bert-base-uncased\")\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "# # Torchvision model for images\n",
    "# image_model = models.resnet101(pretrained=True)\n",
    "# image_model = nn.Sequential(*list(image_model.children())[:-1])  # Remove the last FC layer\n",
    "\n",
    "\n",
    "# def collate_fn(batch):\n",
    "#     images, texts, labels = zip(*batch)\n",
    "\n",
    "#     # Pad sequences\n",
    "#     input_ids = pad_sequence([t['input_ids'] for t in texts])\n",
    "#     attention_mask = pad_sequence([t['attention_mask'] for t in texts])\n",
    "\n",
    "#     # Convert to tensors\n",
    "#     input_ids = torch.as_tensor(input_ids, dtype=torch.long)\n",
    "#     attention_mask = torch.as_tensor(attention_mask, dtype=torch.long)\n",
    "#     labels = torch.as_tensor(labels, dtype=torch.long)\n",
    "\n",
    "#     # Transpose image tensor (batch_size should be first)\n",
    "#     images = torch.stack(images).transpose(0, 1)\n",
    "    \n",
    "#     return images, {'input_ids': input_ids, 'attention_mask': attention_mask}, labels\n",
    "\n",
    "\n",
    "# class HatefulMemesDataset(Dataset):\n",
    "#     def __init__(self, json_file, img_dir, transforms=None):\n",
    "#         self.data = pd.read_json(json_file, lines=True)\n",
    "#         self.img_dir = img_dir\n",
    "#         self.transforms = transforms\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return len(self.data)\n",
    "\n",
    "#     def __getitem__(self, idx):\n",
    "#         img_id = self.data.loc[idx, 'img']\n",
    "#         img_path = os.path.join(self.img_dir, img_id)\n",
    "#         image = Image.open(img_path).convert('RGB')\n",
    "\n",
    "#         if self.transforms:\n",
    "#             image = self.transforms(image)\n",
    "        \n",
    "#         # Process text data\n",
    "#         text = self.data.loc[idx, 'text']\n",
    "#         text = tokenizer(text, return_tensors='pt', padding=\"max_length\", truncation=True, max_length=64)\n",
    "\n",
    "#         label = self.data.loc[idx, 'label']\n",
    "\n",
    "#         return image, text, label\n",
    "\n",
    "\n",
    "# # Define your transforms\n",
    "# transforms = T.Compose([\n",
    "#     T.Resize((224, 224)),\n",
    "#     T.ToTensor(),\n",
    "#     T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),  # normalization settings for resnet models\n",
    "# ])\n",
    "\n",
    "# # Initialize your dataset\n",
    "# dataset = HatefulMemesDataset(json_file=\"data/train.jsonl\",\n",
    "#                               img_dir=\"data\",\n",
    "#                               transforms=transforms)\n",
    "\n",
    "# # Create DataLoader\n",
    "# dataloader = DataLoader(dataset, batch_size=8, shuffle=True, collate_fn=collate_fn)\n",
    "\n",
    "# # # Define a simple model for classification\n",
    "# class CombinedModel(nn.Module):\n",
    "#     def __init__(self, text_model, image_model):\n",
    "#         super(CombinedModel, self).__init__()\n",
    "#         self.text_model = text_model\n",
    "#         self.image_model = image_model\n",
    "#         self.classifier = nn.Linear(text_model.config.hidden_size + 2048, 2)  # 2048 is the output size of resnet101\n",
    "\n",
    "#     def forward(self, image, input_ids, attention_mask):\n",
    "#         text_features = self.text_model(input_ids=input_ids, attention_mask=attention_mask).last_hidden_state[:, 0, :]\n",
    "#         image_features = self.image_model(image).view(image.size(0), -1)\n",
    "#         combined = torch.cat((text_features, image_features), dim=1)\n",
    "#         logits = self.classifier(combined)\n",
    "#         return logits\n",
    "\n",
    "\n",
    "# # Create your model\n",
    "# # model = CombinedModel(text_model, image_model)\n",
    "\n",
    "# # Move to GPU if available\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# image_model = image_model.to(device)\n",
    "\n",
    "# text_model = text_model.to(device)\n",
    "\n",
    "# # Loss and Optimizer\n",
    "# criterion = nn.BinaryCrossEntropyLoss()\n",
    "# text_optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "# image_optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "# # Training loop\n",
    "# num_epochs = 10\n",
    "# model.train()\n",
    "# for epoch in range(num_epochs):\n",
    "#     for images, texts, labels in dataloader:\n",
    "#         # Move inputs and targets to the same device as the model\n",
    "#         images = images.permute(1, 0, 2, 3)\n",
    "#         images = images.to(device)\n",
    "#         input_ids = texts['input_ids'].squeeze().to(device)\n",
    "# #         print(\"text attention mask\", texts['attention_mask'])\n",
    "#         attention_mask = texts['attention_mask'].squeeze().to(device)\n",
    "#         labels = labels.to(device)\n",
    "\n",
    "#         # Forward pass\n",
    "# #         logits = model(images, input_ids, attention_mask)\n",
    "#         text_features = text_model(input_ids=input_ids, attention_mask=attention_mask).last_hidden_state[:, 0, :]\n",
    "#         image_features = image_model(image).view(image.size(0), -1)\n",
    "#         combined = torch.cat((text_features, image_features), dim=1)\n",
    "\n",
    "#         # Compute the loss\n",
    "#         loss = criterion(logits, labels)\n",
    "\n",
    "#         # Backward pass and optimization\n",
    "#         loss.backward()\n",
    "#         text_optimizer.step()\n",
    "        \n",
    "#         optimizer.zero_grad()\n",
    "\n",
    "#     print(f\"Epoch: {epoch}, Loss: {loss.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d489cf63",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
