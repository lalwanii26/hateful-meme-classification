{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc7e9005",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install torch\n",
    "# !pip install transformers\n",
    "# !pip install sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "58d6cc8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# f = pd.read_json(file_path, lines=True)\n",
    "df_image_train = pd.read_json(\"data/train.jsonl\", lines=True)\n",
    "df_image_val = pd.read_json(\"data/dev.jsonl\", lines=True)\n",
    "df_image_test = pd.read_json(\"data/test.jsonl\", lines=True)\n",
    "# df_image_val.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3dc19b53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8addbc3f857840609eae0802151725ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)e9125/.gitattributes:   0%|          | 0.00/1.18k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe6ca17652fc492aa23e12168c1f7e07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94200a1c409e40cfbc0e674c43c4228c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)7e55de9125/README.md:   0%|          | 0.00/10.6k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afcc54dc7a1046bbaffdee5b2760f592",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)55de9125/config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e8e6cf225cb475aa2b6865d6abb84ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)ce_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cdee11367aa34b7e97c8ad42d019ba81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)125/data_config.json:   0%|          | 0.00/39.3k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa6990279e7c4effa4c07754dc17fd0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd6f7e7cfe8e4916b4948d437698ebe8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)nce_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bd4919f1ebb48c4a66997734802d0a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41f38cefb9744148ae1aab9c8b84aa8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)e9125/tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73f5b76b218f4bd480cd6a9faeb2efb5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7856d3301354a439b6fefefe073890d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)9125/train_script.py:   0%|          | 0.00/13.2k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c3825a7a23d44cb934ea97018364246",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)7e55de9125/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df2e51bf4b8c4b25b0b5ec9e5a52966b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)5de9125/modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: This framework generates embeddings for each input sentence\n",
      "Embedding: [-1.37173804e-02 -4.28515561e-02 -1.56286024e-02  1.40537508e-02\n",
      "  3.95537391e-02  1.21796280e-01  2.94333510e-02 -3.17524113e-02\n",
      "  3.54960039e-02 -7.93140307e-02  1.75878033e-02 -4.04369645e-02\n",
      "  4.97259721e-02  2.54912451e-02 -7.18699768e-02  8.14968497e-02\n",
      "  1.47072645e-03  4.79627475e-02 -4.50335816e-02 -9.92174968e-02\n",
      " -2.81769224e-02  6.45045936e-02  4.44670171e-02 -4.76217456e-02\n",
      " -3.52952406e-02  4.38671671e-02 -5.28566018e-02  4.33030014e-04\n",
      "  1.01921484e-01  1.64072271e-02  3.26996669e-02 -3.45986858e-02\n",
      "  1.21339718e-02  7.94871300e-02  4.58339276e-03  1.57778822e-02\n",
      " -9.68210492e-03  2.87626311e-02 -5.05806357e-02 -1.55793801e-02\n",
      " -2.87907030e-02 -9.62281227e-03  3.15556228e-02  2.27349456e-02\n",
      "  8.71449560e-02 -3.85027453e-02 -8.84718671e-02 -8.75497982e-03\n",
      " -2.12343298e-02  2.08924189e-02 -9.02078301e-02 -5.25732413e-02\n",
      " -1.05638728e-02  2.88311131e-02 -1.61454789e-02  6.17839675e-03\n",
      " -1.23234186e-02 -1.07337004e-02  2.83353440e-02 -5.28567955e-02\n",
      " -3.58618014e-02 -5.97989075e-02 -1.09055005e-02  2.91566513e-02\n",
      "  7.97979310e-02 -3.27905931e-04  6.83496427e-03  1.32718654e-02\n",
      " -4.24619988e-02  1.87656879e-02 -9.89234373e-02  2.09050123e-02\n",
      " -8.69605988e-02 -1.50152054e-02 -4.86202352e-02  8.04414824e-02\n",
      " -3.67701426e-03 -6.65044487e-02  1.14556760e-01 -3.04228310e-02\n",
      "  2.96631362e-02 -2.80694906e-02  4.64990437e-02 -2.25513969e-02\n",
      "  8.54223222e-02  3.15446742e-02  7.34541938e-02 -2.21861750e-02\n",
      " -5.29679097e-02  1.27130458e-02 -5.27339950e-02 -1.06188767e-01\n",
      "  7.04731569e-02  2.76736394e-02 -8.05530995e-02  2.39649713e-02\n",
      " -2.65124906e-02 -2.17331313e-02  4.35275324e-02  4.84711938e-02\n",
      " -2.37066932e-02  2.85768751e-02  1.11846142e-01 -6.34936243e-02\n",
      " -1.58318672e-02 -2.26169880e-02 -1.31028201e-02 -1.62071199e-03\n",
      " -3.60928923e-02 -9.78297442e-02 -4.67729531e-02  1.76272057e-02\n",
      " -3.97492275e-02 -1.76426329e-04  3.39627750e-02 -2.09633894e-02\n",
      "  6.33659121e-03 -2.59411559e-02  8.10410753e-02  6.14393130e-02\n",
      " -5.44600701e-03  6.48275986e-02 -1.16844065e-01  2.36860942e-02\n",
      " -1.32058552e-02 -1.12476453e-01  1.90049466e-02 -1.74660599e-34\n",
      "  5.58949672e-02  1.94244403e-02  4.65438776e-02  5.18645607e-02\n",
      "  3.89390141e-02  3.40541005e-02 -4.32114415e-02  7.90637434e-02\n",
      " -9.79530364e-02 -1.27441250e-02 -2.91870795e-02  1.02052316e-02\n",
      "  1.88115910e-02  1.08942553e-01  6.63464963e-02 -5.35295159e-02\n",
      " -3.29229012e-02  4.69826721e-02  2.28883103e-02  2.74114646e-02\n",
      " -2.91983485e-02  3.12706344e-02 -2.22850814e-02 -1.02282144e-01\n",
      " -2.79116798e-02  1.13793286e-02  9.06309038e-02 -4.75414544e-02\n",
      " -1.00718938e-01 -1.23232119e-02 -7.96928406e-02 -1.44636529e-02\n",
      " -7.76400566e-02 -7.66920485e-03  9.73955542e-03  2.24204753e-02\n",
      "  7.77267888e-02 -3.17155849e-03  2.11538505e-02 -3.30393985e-02\n",
      "  9.55248810e-03 -3.73012014e-02  2.61360351e-02 -9.79083031e-03\n",
      " -6.31505325e-02  5.77436853e-03 -3.80031578e-02  1.29684182e-02\n",
      " -1.82498898e-02 -1.56282950e-02 -1.23359286e-03  5.55579402e-02\n",
      "  1.13112706e-04 -5.61256818e-02  7.40165859e-02  1.84452068e-02\n",
      " -2.66368333e-02  1.31951850e-02  7.50086606e-02 -2.46797539e-02\n",
      " -3.24006192e-02 -1.57674737e-02 -8.03513546e-03 -5.61318407e-03\n",
      "  1.05687594e-02  3.26173822e-03 -3.91990319e-02 -9.38677043e-02\n",
      "  1.14227146e-01  6.57304749e-02 -4.72633094e-02  1.45087829e-02\n",
      " -3.54490504e-02 -3.37761641e-02 -5.15506119e-02 -3.80999781e-03\n",
      " -5.15036210e-02 -5.93429990e-02 -1.69410568e-03  7.42107481e-02\n",
      " -4.20091376e-02 -7.19975159e-02  3.17250155e-02 -1.66303609e-02\n",
      "  3.96984816e-03 -6.52750805e-02  2.77391262e-02 -7.51649961e-02\n",
      "  2.27456149e-02 -3.91368233e-02  1.54315867e-02 -5.54908514e-02\n",
      "  1.23318192e-02 -2.59520598e-02  6.66423514e-02 -6.91259509e-34\n",
      "  3.31628695e-02  8.47928822e-02 -6.65584058e-02  3.33541557e-02\n",
      "  4.71608667e-03  1.35361804e-02 -5.38694337e-02  9.20694023e-02\n",
      " -2.96876617e-02  3.16219740e-02 -2.37497669e-02  1.98771041e-02\n",
      "  1.03446163e-01 -9.06947404e-02  6.30628876e-03  1.42886238e-02\n",
      "  1.19293500e-02  6.43731048e-03  4.20104563e-02  1.25344954e-02\n",
      "  3.93019393e-02  5.35691381e-02 -4.30749841e-02  6.10432848e-02\n",
      " -5.39360553e-05  6.91682622e-02  1.05520561e-02  1.22111533e-02\n",
      " -7.23185614e-02  2.50469148e-02 -5.18370941e-02 -4.36562598e-02\n",
      " -6.71818182e-02  1.34828128e-02 -7.25888833e-02  7.04162661e-03\n",
      "  6.58939332e-02  1.08993854e-02 -2.60010920e-03  5.49969077e-02\n",
      "  5.06967194e-02  3.27948555e-02 -6.68833032e-02  6.45557120e-02\n",
      " -2.52076536e-02 -2.92572007e-02 -1.16696760e-01  3.24064456e-02\n",
      "  5.85858710e-02 -3.51756327e-02 -7.15240017e-02  2.24935990e-02\n",
      " -1.00786731e-01 -4.74544801e-02 -7.61962533e-02 -5.87166809e-02\n",
      "  4.21138369e-02 -7.47213736e-02  1.98468417e-02 -3.36504751e-03\n",
      " -5.29736690e-02  2.74728984e-02  3.45736742e-02 -6.11846857e-02\n",
      "  1.06364779e-01 -9.64120105e-02 -4.55944985e-02  1.51490094e-02\n",
      " -5.13530383e-03 -6.64447546e-02  4.31721509e-02 -1.10405590e-02\n",
      " -9.80253890e-03  7.53783211e-02 -1.49570992e-02 -4.80208807e-02\n",
      "  5.80726415e-02 -2.43896618e-02 -2.23138109e-02 -4.36992832e-02\n",
      "  5.12054116e-02 -3.28625739e-02  1.08763322e-01  6.08926043e-02\n",
      "  3.30793415e-03  5.53820319e-02  8.43200833e-02  1.27087301e-02\n",
      "  3.84465680e-02  6.52326047e-02 -2.94683855e-02  5.08005582e-02\n",
      " -2.09348276e-02  1.46135673e-01  2.25561652e-02 -1.77227779e-08\n",
      " -5.02672754e-02 -2.79213622e-04 -1.00328535e-01  2.42811311e-02\n",
      " -7.54043236e-02 -3.79139893e-02  3.96049805e-02  3.10079884e-02\n",
      " -9.05705430e-03 -6.50411844e-02  4.05453332e-02  4.83390428e-02\n",
      " -4.56962436e-02  4.76003485e-03  2.64365342e-03  9.35614556e-02\n",
      " -4.02599089e-02  3.27402167e-02  1.18298465e-02  5.54344654e-02\n",
      "  1.48052230e-01  7.21189529e-02  2.76969542e-04  1.68651622e-02\n",
      "  8.34880210e-03 -8.76153447e-03 -1.33649968e-02  6.14236519e-02\n",
      "  1.57168005e-02  6.94960877e-02  1.08621782e-02  6.08018450e-02\n",
      " -5.33421189e-02 -3.47924680e-02 -3.36272120e-02  6.93906993e-02\n",
      "  1.22987805e-02 -1.45237356e-01 -2.06969958e-03 -4.61132899e-02\n",
      "  3.72747425e-03 -5.59357274e-03 -1.00659840e-01 -4.45953235e-02\n",
      "  5.40921278e-02  4.98897117e-03  1.49534456e-02 -8.26059431e-02\n",
      "  6.26630336e-02 -5.01910783e-03 -4.81857844e-02 -3.53991315e-02\n",
      "  9.03388951e-03 -2.42337696e-02  5.66267595e-02  2.51528919e-02\n",
      " -1.70709323e-02 -1.24780117e-02  3.19518223e-02  1.38421198e-02\n",
      " -1.55814681e-02  1.00178316e-01  1.23657271e-01 -4.22967076e-02]\n",
      "\n",
      "Sentence: Sentences are passed as a list of string.\n",
      "Embedding: [ 5.64524755e-02  5.50023913e-02  3.13795693e-02  3.39485072e-02\n",
      " -3.54247205e-02  8.34667683e-02  9.88800749e-02  7.27546960e-03\n",
      " -6.68660412e-03 -7.65808113e-03  7.93738663e-02  7.39702606e-04\n",
      "  1.49291754e-02 -1.51046673e-02  3.67674418e-02  4.78743315e-02\n",
      " -4.81969677e-02 -3.76052633e-02 -4.60277908e-02 -8.89816210e-02\n",
      "  1.20228164e-01  1.30663306e-01 -3.73936221e-02  2.47855787e-03\n",
      "  2.55824765e-03  7.25814924e-02 -6.80436492e-02 -5.24695888e-02\n",
      "  4.90234159e-02  2.99563445e-02 -5.84429689e-02 -2.02263109e-02\n",
      "  2.08821949e-02  9.76691917e-02  3.52390781e-02  3.91140878e-02\n",
      "  1.05667925e-02  1.56231888e-03 -1.30822640e-02  8.52904934e-03\n",
      " -4.84092813e-03 -2.03766655e-02 -2.71800794e-02  2.83307694e-02\n",
      "  3.66017744e-02  2.51276158e-02 -9.90861952e-02  1.15626408e-02\n",
      " -3.60380597e-02 -7.23783895e-02 -1.12670109e-01  1.12942290e-02\n",
      " -3.86397541e-02  4.67386059e-02 -2.88460609e-02  2.26704124e-02\n",
      " -8.52403883e-03  3.32814865e-02 -1.06581894e-03 -7.09744841e-02\n",
      " -6.31170198e-02 -5.72186671e-02 -6.16026297e-02  5.47146797e-02\n",
      "  1.18317986e-02 -4.66261394e-02  2.56960150e-02 -7.07413489e-03\n",
      " -5.73842935e-02  4.12839092e-02 -5.91503568e-02  5.89021631e-02\n",
      " -4.41697873e-02  4.65081483e-02 -3.15814503e-02  5.58312461e-02\n",
      "  5.54578640e-02 -5.96533269e-02  4.06407751e-02  4.83765732e-03\n",
      " -4.96768467e-02 -1.00944333e-01  3.40078361e-02  4.13274858e-03\n",
      " -2.93530780e-03  2.11837646e-02 -3.73962224e-02 -2.79067028e-02\n",
      " -4.61768061e-02  5.26138805e-02 -2.79734898e-02 -1.62379295e-01\n",
      "  6.61042556e-02  1.72274541e-02 -5.45113115e-03  4.74474095e-02\n",
      " -3.82237658e-02 -3.96896526e-02  1.34545024e-02  4.49653715e-02\n",
      "  4.53670416e-03  2.82978285e-02  8.36632997e-02 -1.00857820e-02\n",
      " -1.19354032e-01 -3.84624302e-02  4.82859015e-02 -9.46083814e-02\n",
      "  1.91854369e-02 -9.96518657e-02 -6.30596727e-02  3.02696358e-02\n",
      "  1.17402431e-02 -4.78372648e-02 -6.20274572e-03 -3.32850814e-02\n",
      " -4.04390600e-03  1.28307231e-02  4.05254923e-02  7.56477043e-02\n",
      "  2.92434990e-02  2.84270141e-02 -2.78938506e-02  1.66857801e-02\n",
      " -2.47961748e-02 -6.83651119e-02  2.89968420e-02 -5.39867858e-33\n",
      " -2.69013946e-03 -2.65068747e-02 -6.47865934e-04 -8.46206304e-03\n",
      " -7.35154673e-02  4.94081806e-03 -5.97842447e-02  1.03438338e-02\n",
      "  2.12902040e-03 -2.88213091e-03 -3.17076743e-02 -9.42363888e-02\n",
      "  3.03019769e-02  7.00226873e-02  4.50685397e-02  3.69439349e-02\n",
      "  1.13594104e-02  3.53027284e-02  5.50449546e-03  1.34416251e-03\n",
      "  3.46119562e-03  7.75048062e-02  5.45112565e-02 -7.92055950e-02\n",
      " -9.31696668e-02 -4.03398424e-02  3.10668536e-02 -3.83081585e-02\n",
      " -5.89442700e-02  1.93331949e-02 -2.67159808e-02 -7.91938528e-02\n",
      "  1.04231112e-04  7.70621076e-02  4.16604020e-02  8.90932605e-02\n",
      "  3.56843472e-02 -1.09152915e-02  3.71498354e-02 -2.07070690e-02\n",
      " -2.46100686e-02 -2.05025803e-02  2.62201745e-02  3.43590491e-02\n",
      "  4.39251065e-02 -8.20518192e-03 -8.40710700e-02  4.24170904e-02\n",
      "  4.87498567e-02  5.95384650e-02  2.87747774e-02  3.37638482e-02\n",
      " -4.07442749e-02 -1.66368694e-03  7.91927427e-02  3.41088548e-02\n",
      " -5.72819961e-04  1.87749676e-02 -1.36964135e-02  7.38333240e-02\n",
      "  5.74428937e-04  8.33505243e-02  5.60811087e-02 -1.13711124e-02\n",
      "  4.42611314e-02  2.69581825e-02 -4.80535813e-02 -3.15087438e-02\n",
      "  7.75225908e-02  1.81773622e-02 -8.83005261e-02 -7.85518996e-03\n",
      " -6.22243099e-02  7.19372481e-02 -2.33475156e-02  6.52482780e-03\n",
      " -9.49527696e-03 -9.88312811e-02  4.01306041e-02  3.07396706e-02\n",
      " -2.21607238e-02 -9.45911556e-02  1.02367802e-02  1.02187745e-01\n",
      " -4.12960127e-02 -3.15777846e-02  4.74751852e-02 -1.10209838e-01\n",
      "  1.69615094e-02 -3.71709205e-02 -1.03262113e-02 -4.72538583e-02\n",
      " -1.20214568e-02 -1.93255134e-02  5.79292215e-02  4.23865952e-34\n",
      "  3.92013304e-02  8.41361359e-02 -1.02946743e-01  6.92259446e-02\n",
      "  1.68821365e-02 -3.26760784e-02  9.65962186e-03  1.80899650e-02\n",
      "  2.17939764e-02  1.63189098e-02 -9.69292223e-02  3.74852214e-03\n",
      " -2.38457359e-02 -3.44055854e-02  7.11962655e-02  9.21939733e-04\n",
      " -6.23862864e-03  3.23754400e-02 -8.90380412e-04  5.01906639e-03\n",
      " -4.24537808e-02  9.89083871e-02 -4.60321084e-02  4.69704941e-02\n",
      " -1.75283868e-02 -7.02518038e-03  1.32743921e-02 -5.30152135e-02\n",
      "  2.66402611e-03  1.45819252e-02  7.43345823e-03 -3.07132043e-02\n",
      " -2.09416524e-02  8.24109986e-02 -5.15894629e-02 -2.71178279e-02\n",
      "  1.17582999e-01  7.72503624e-03 -1.89522766e-02  3.94559279e-02\n",
      "  7.17360452e-02  2.59117540e-02  2.75191702e-02  9.50542279e-03\n",
      " -3.02355196e-02 -4.07944471e-02 -1.04028471e-01 -7.97418784e-03\n",
      " -3.64453555e-03  3.29716168e-02 -2.35954411e-02 -7.50518031e-03\n",
      " -5.82233779e-02 -3.17906104e-02 -4.18049060e-02  2.17453465e-02\n",
      " -6.67292327e-02 -4.89104278e-02  4.58515761e-03 -2.66046673e-02\n",
      " -1.12597056e-01  5.11167012e-02  5.48534207e-02 -6.69856817e-02\n",
      "  1.26766279e-01 -8.59488025e-02 -5.94231263e-02 -2.92189000e-03\n",
      " -1.14875827e-02 -1.26025900e-01 -3.48280719e-03 -9.12001655e-02\n",
      " -1.22933082e-01  1.33777643e-02 -4.75775450e-02 -6.57933205e-02\n",
      " -3.39410156e-02 -3.07107884e-02 -5.22033907e-02 -2.35463642e-02\n",
      "  5.90035319e-02 -3.85757834e-02  3.19701284e-02  4.05118614e-02\n",
      "  1.67077780e-02 -3.58281508e-02  1.45687955e-02  3.20138074e-02\n",
      " -1.34843737e-02  6.07819781e-02 -8.31401069e-03 -1.08105782e-02\n",
      "  4.69410606e-02  7.66134113e-02 -4.23400067e-02 -2.11963371e-08\n",
      " -7.25292861e-02 -4.20227908e-02 -6.12374544e-02  5.24666086e-02\n",
      " -1.42363524e-02  1.18487412e-02 -1.40788965e-02 -3.67529988e-02\n",
      " -4.44977246e-02 -1.15140863e-02  5.23316935e-02  2.96652149e-02\n",
      " -4.62781116e-02 -3.70892771e-02  1.89129710e-02  2.04307586e-02\n",
      " -2.24005990e-02 -1.48562761e-02 -1.79503970e-02  4.20007892e-02\n",
      "  1.40942410e-02 -2.83492785e-02 -1.16863027e-01  1.48957046e-02\n",
      " -7.30604690e-04  5.66028021e-02 -2.68740430e-02  1.09106675e-01\n",
      "  2.94566527e-03  1.19267911e-01  1.14212438e-01  8.92973691e-02\n",
      " -1.70255415e-02 -4.99054156e-02 -2.11930890e-02  3.18421572e-02\n",
      "  7.03436211e-02 -1.02929451e-01  8.23816806e-02  2.81968210e-02\n",
      "  3.21146511e-02  3.79108377e-02 -1.09553121e-01  8.19620341e-02\n",
      "  8.73216316e-02 -5.73564023e-02 -2.01708917e-02 -5.69444075e-02\n",
      " -1.30338352e-02 -5.55684865e-02 -1.32966489e-02  8.64007510e-03\n",
      "  5.30011877e-02 -4.06847224e-02  2.71709133e-02 -2.55948585e-03\n",
      "  3.05775534e-02 -4.61865179e-02  4.68033599e-03 -3.64947021e-02\n",
      "  6.80802613e-02  6.65087625e-02  8.49152356e-02 -3.32849249e-02]\n",
      "\n",
      "Sentence: The quick brown fox jumps over the lazy dog.\n",
      "Embedding: [ 4.39335518e-02  5.89343682e-02  4.81783859e-02  7.75481090e-02\n",
      "  2.67444104e-02 -3.76295969e-02 -2.60512927e-03 -5.99430203e-02\n",
      " -2.49602692e-03  2.20728144e-02  4.80259582e-02  5.57553023e-02\n",
      " -3.89454141e-02 -2.66168024e-02  7.69342063e-03 -2.62376387e-02\n",
      " -3.64160724e-02 -3.78161296e-02  7.40781575e-02 -4.95050512e-02\n",
      " -5.85217327e-02 -6.36197180e-02  3.24349888e-02  2.20085196e-02\n",
      " -7.10637718e-02 -3.31577845e-02 -6.94104135e-02 -5.00374548e-02\n",
      "  7.46268034e-02 -1.11133814e-01 -1.23063410e-02  3.77456322e-02\n",
      " -2.80313175e-02  1.45353368e-02 -3.15585472e-02 -8.05836841e-02\n",
      "  5.83525896e-02  2.59008491e-03  3.92802581e-02  2.57696044e-02\n",
      "  4.98505533e-02 -1.75622769e-03 -4.55298051e-02  2.92607751e-02\n",
      " -1.02017276e-01  5.22287525e-02 -7.90899843e-02 -1.02857500e-02\n",
      "  9.20248125e-03  1.30732385e-02 -4.04777452e-02 -2.77924985e-02\n",
      "  1.24667538e-02  6.72832951e-02  6.81248382e-02 -7.57122086e-03\n",
      " -6.09947601e-03 -4.23777103e-02  5.17815948e-02 -1.56707130e-02\n",
      "  9.56359133e-03  4.12390418e-02  2.14959234e-02  1.04293460e-02\n",
      "  2.73349397e-02  1.87062416e-02 -2.69607175e-02 -7.00541958e-02\n",
      " -1.04700506e-01 -1.89876580e-03  1.77016854e-02 -5.74725494e-02\n",
      " -1.44223254e-02  4.70469240e-04  2.33226269e-03 -2.51920428e-02\n",
      "  4.93004173e-02 -5.09609580e-02  6.31982908e-02  1.49165383e-02\n",
      " -2.70766653e-02 -4.52875793e-02 -4.90593947e-02  3.74940932e-02\n",
      "  3.84579487e-02  1.56902603e-03  3.09922453e-02  2.01630387e-02\n",
      " -1.24363480e-02 -3.06719858e-02 -2.78819446e-02 -6.89182803e-02\n",
      " -5.13677746e-02  2.14795396e-02  1.15747098e-02  1.25406671e-03\n",
      "  1.88765880e-02 -4.42318805e-02 -4.49817143e-02 -3.41866608e-03\n",
      "  1.31131113e-02  2.00099256e-02  1.21099785e-01  2.31074803e-02\n",
      " -2.20160037e-02 -3.28846909e-02 -3.15513997e-03  1.17834585e-04\n",
      "  9.91498753e-02  1.65239032e-02 -4.69667464e-03 -1.45366890e-02\n",
      " -3.71075142e-03  9.65136290e-02  2.85908077e-02  2.13482101e-02\n",
      " -7.17644915e-02 -2.41142306e-02 -4.40940335e-02 -1.07346877e-01\n",
      "  6.79945499e-02  1.30466834e-01 -7.97029585e-02  6.79509714e-03\n",
      " -2.37511992e-02 -4.61636595e-02 -2.99650598e-02 -3.69410120e-33\n",
      "  7.30969831e-02 -2.20172182e-02 -8.61464441e-02 -7.14379326e-02\n",
      " -6.36741295e-02 -7.21863061e-02 -5.93044143e-03 -2.33641677e-02\n",
      " -2.83658262e-02  4.77434881e-02 -8.06176588e-02 -1.56481564e-03\n",
      "  1.38443764e-02 -2.86236182e-02 -3.35386992e-02 -1.13777541e-01\n",
      " -9.17633809e-03 -1.08101154e-02  3.23196203e-02  5.88380247e-02\n",
      "  3.34208943e-02  1.07987948e-01 -3.72713171e-02 -2.96770334e-02\n",
      "  5.17189652e-02 -2.25338917e-02 -6.96091205e-02 -2.14475542e-02\n",
      " -2.33410634e-02  4.82199825e-02 -3.58766466e-02 -4.68990915e-02\n",
      " -3.97873484e-02  1.10813268e-01 -1.43007403e-02 -1.18464477e-01\n",
      "  5.82915172e-02 -6.25889078e-02 -2.94040721e-02  6.03238232e-02\n",
      " -2.44414527e-03  1.60116218e-02  2.67233383e-02  2.49530710e-02\n",
      " -6.49319217e-02 -1.06802462e-02  2.81464625e-02  1.03563257e-02\n",
      " -6.63571351e-04  1.98186226e-02 -3.04288417e-02  6.28424250e-03\n",
      "  5.15268408e-02 -4.75375429e-02 -6.44421354e-02  9.55032408e-02\n",
      "  7.55858421e-02 -2.81574931e-02 -3.49966027e-02  1.01816408e-01\n",
      "  1.98732372e-02 -3.68036777e-02  2.93520140e-03 -5.00745587e-02\n",
      "  1.50932148e-01 -6.16079606e-02 -8.58812705e-02  7.13993423e-03\n",
      " -1.33065740e-02  7.80404732e-02  1.75250247e-02  4.21279483e-02\n",
      "  3.57940048e-02 -1.32950425e-01  3.56970169e-02 -2.03116778e-02\n",
      "  1.24909896e-02 -3.80355194e-02  4.91543338e-02 -1.56540908e-02\n",
      "  1.21418245e-01 -8.08644593e-02 -4.68781404e-02  4.10843007e-02\n",
      " -1.84317902e-02  6.69691414e-02  4.33595153e-03  2.27315426e-02\n",
      " -1.36429071e-02 -4.53238413e-02 -3.92829701e-02 -6.29891036e-03\n",
      "  5.29609695e-02 -3.69065106e-02  7.11677447e-02  2.33343269e-33\n",
      "  1.05231375e-01 -4.81874384e-02  6.95918798e-02  6.56976476e-02\n",
      " -4.65149470e-02  5.14492393e-02 -1.24475341e-02  3.20872292e-02\n",
      " -9.23356563e-02  5.00932746e-02 -3.28876488e-02  1.39139118e-02\n",
      " -8.70246615e-04 -4.90904460e-03  1.03946395e-01  3.21620930e-04\n",
      "  5.28110154e-02 -1.17990365e-02  2.31565107e-02  1.31767904e-02\n",
      " -5.25962897e-02  3.26702036e-02  3.08719609e-04  6.41129017e-02\n",
      "  3.88500988e-02  5.88008314e-02  8.29793364e-02 -1.88149232e-02\n",
      " -2.26377118e-02 -1.00473635e-01 -3.83752249e-02 -5.88081218e-02\n",
      "  1.82421715e-03 -4.26995233e-02  2.50195023e-02  6.40059933e-02\n",
      " -3.77483182e-02 -6.83900807e-03 -2.54605827e-03 -9.76042822e-02\n",
      "  1.88476015e-02 -8.83176457e-04  1.73611697e-02  7.10790232e-02\n",
      "  3.30393091e-02  6.93425816e-03 -5.60523383e-02  5.14634103e-02\n",
      " -4.29542214e-02  4.60076630e-02 -8.78833141e-03  3.17289308e-02\n",
      "  4.93965633e-02  2.95189712e-02 -5.05192466e-02 -5.43187149e-02\n",
      "  1.49964995e-04 -2.76614632e-02  3.46877985e-02 -2.10890137e-02\n",
      "  1.38060348e-02  2.99886838e-02  1.39744608e-02 -4.26469184e-03\n",
      " -1.50337163e-02 -8.76095220e-02 -6.85053766e-02 -4.28141728e-02\n",
      "  7.76944980e-02 -7.10285380e-02 -7.37691857e-03  2.13727262e-02\n",
      "  1.35562327e-02 -7.90464729e-02  5.47669642e-03  8.30663666e-02\n",
      "  1.14148043e-01  1.80764520e-03  8.75491425e-02 -4.16045226e-02\n",
      "  1.55416466e-02 -1.01206452e-02 -7.32437801e-03  1.07965842e-02\n",
      " -6.62816614e-02  3.98413911e-02 -1.16711587e-01  6.42993897e-02\n",
      "  4.02920060e-02 -6.54741526e-02  1.95052605e-02  8.09995681e-02\n",
      "  5.36463410e-02  7.67969638e-02 -1.34852324e-02 -1.76919084e-08\n",
      " -4.43935096e-02  9.20642167e-03 -8.79590288e-02  4.26921658e-02\n",
      "  7.31365010e-02  1.68427248e-02 -4.03263085e-02  1.85131468e-02\n",
      "  8.44172537e-02 -3.74477394e-02  3.02996244e-02  2.90641822e-02\n",
      "  6.36878833e-02  2.89750230e-02 -1.47269825e-02  1.77542828e-02\n",
      " -3.36895213e-02  1.73161216e-02  3.37875187e-02  1.76826075e-01\n",
      " -1.75533630e-02 -6.03077821e-02 -1.43394582e-02 -2.38536559e-02\n",
      " -4.45530191e-02 -2.89850570e-02 -8.96776691e-02 -1.75941200e-03\n",
      " -2.61485819e-02  5.93996700e-03 -5.18355444e-02  8.57279748e-02\n",
      " -8.18399116e-02  8.35441053e-03  4.00790386e-02  4.17764448e-02\n",
      "  1.04573578e-01 -2.86564953e-03  1.96691062e-02  5.81048708e-03\n",
      "  1.33253522e-02  4.51001078e-02 -2.17588302e-02 -1.39493020e-02\n",
      " -6.86992407e-02 -2.94111297e-03 -3.10765114e-02 -1.05854370e-01\n",
      "  6.91623986e-02 -4.24114726e-02 -4.67682257e-02 -3.64750735e-02\n",
      "  4.50399965e-02  6.09817058e-02 -6.56561926e-02 -5.45643736e-03\n",
      " -1.86226945e-02 -6.31484389e-02 -3.87436859e-02  3.46733704e-02\n",
      "  5.55458069e-02  5.21628074e-02  5.61065413e-02  1.02063939e-01]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "#Our sentences we like to encode\n",
    "sentences = ['This framework generates embeddings for each input sentence',\n",
    "    'Sentences are passed as a list of string.',\n",
    "    'The quick brown fox jumps over the lazy dog.']\n",
    "\n",
    "#Sentences are encoded by calling model.encode()\n",
    "embeddings = model.encode(sentences)\n",
    "\n",
    "#Print the embeddings\n",
    "for sentence, embedding in zip(sentences, embeddings):\n",
    "    print(\"Sentence:\", sentence)\n",
    "    print(\"Embedding:\", embedding)\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4133dee6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-15 17:12:56.805684: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-06-15 17:12:57.661009: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4bba4f8a0104fdf8ff90deb248748cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)821d1/.gitattributes:   0%|          | 0.00/391 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d534778924be4d6a9df4bf40bebc3ab9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3e270c543ba4f76a6e7897e44277ceb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)8d01e821d1/README.md:   0%|          | 0.00/3.95k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48a5f1f6da71423aa800b0e3daa0d65d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)d1/added_tokens.json:   0%|          | 0.00/2.00 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df7da297ad7a4d71b8a886f6833aaa90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)01e821d1/config.json:   0%|          | 0.00/625 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6297c95768ec4a76a62edc6314bdd70b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)ce_transformers.json:   0%|          | 0.00/122 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8bc788e3f30942ab8af18ae7b78af808",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/438M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f96452696fa4c8dba38f95364ee1410",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)nce_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b07b0bd033f4bcfa769bf3fe6ed5b8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0445662e55a442ff82fd72ea6e22cbfe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)821d1/tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5423e5d35e4142d89ed2ac6cbba6f14b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/399 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b0a75c33cf3413eb310b5c4809c2ea9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)8d01e821d1/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5bd5dab175cd4215b2b1fe67d0e523cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)1e821d1/modules.json:   0%|          | 0.00/229 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alalwani/.local/lib/python3.9/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.7232975363731384\n",
      "Epoch 2, Loss: 1.2013314962387085\n",
      "Epoch 3, Loss: 0.7260332703590393\n",
      "Epoch 4, Loss: 0.8345854878425598\n",
      "Epoch 5, Loss: 0.9182937741279602\n",
      "Epoch 6, Loss: 0.6996355652809143\n",
      "Epoch 7, Loss: 0.6127670407295227\n",
      "Epoch 8, Loss: 0.721567690372467\n",
      "Epoch 9, Loss: 0.7470502257347107\n",
      "Epoch 10, Loss: 0.6665780544281006\n",
      "Epoch 11, Loss: 0.6212952136993408\n",
      "Epoch 12, Loss: 0.6695044636726379\n",
      "Epoch 13, Loss: 0.6784325838088989\n",
      "Epoch 14, Loss: 0.611513614654541\n",
      "Epoch 15, Loss: 0.575916588306427\n",
      "Epoch 16, Loss: 0.607874870300293\n",
      "Epoch 17, Loss: 0.6380871534347534\n",
      "Epoch 18, Loss: 0.624589741230011\n",
      "Epoch 19, Loss: 0.5939586758613586\n",
      "Epoch 20, Loss: 0.5882928371429443\n",
      "Epoch 21, Loss: 0.6006421446800232\n",
      "Epoch 22, Loss: 0.5922693610191345\n",
      "Epoch 23, Loss: 0.5686483979225159\n",
      "Epoch 24, Loss: 0.5685181021690369\n",
      "Epoch 25, Loss: 0.5867200493812561\n",
      "Epoch 26, Loss: 0.5882651805877686\n",
      "Epoch 27, Loss: 0.5709784030914307\n",
      "Epoch 28, Loss: 0.5618368983268738\n",
      "Epoch 29, Loss: 0.5678451061248779\n",
      "Epoch 30, Loss: 0.5683943033218384\n",
      "Epoch 31, Loss: 0.5605127811431885\n",
      "Epoch 32, Loss: 0.5599059462547302\n",
      "Epoch 33, Loss: 0.5662818551063538\n",
      "Epoch 34, Loss: 0.5655683875083923\n",
      "Epoch 35, Loss: 0.5567392706871033\n",
      "Epoch 36, Loss: 0.5528138279914856\n",
      "Epoch 37, Loss: 0.5568358302116394\n",
      "Epoch 38, Loss: 0.5574837923049927\n",
      "Epoch 39, Loss: 0.5533664226531982\n",
      "Epoch 40, Loss: 0.5533249378204346\n",
      "Epoch 41, Loss: 0.5552394390106201\n",
      "Epoch 42, Loss: 0.5522226095199585\n",
      "Epoch 43, Loss: 0.5483914613723755\n",
      "Epoch 44, Loss: 0.5497535467147827\n",
      "Epoch 45, Loss: 0.5516411066055298\n",
      "Epoch 46, Loss: 0.549553394317627\n",
      "Epoch 47, Loss: 0.5477809906005859\n",
      "Epoch 48, Loss: 0.5484675765037537\n",
      "Epoch 49, Loss: 0.5478439331054688\n",
      "Epoch 50, Loss: 0.5458256006240845\n",
      "Epoch 51, Loss: 0.5460051894187927\n",
      "Epoch 52, Loss: 0.5470520257949829\n",
      "Epoch 53, Loss: 0.5458214282989502\n",
      "Epoch 54, Loss: 0.5444086194038391\n",
      "Epoch 55, Loss: 0.5446596145629883\n",
      "Epoch 56, Loss: 0.544487476348877\n",
      "Epoch 57, Loss: 0.5435129404067993\n",
      "Epoch 58, Loss: 0.5434945225715637\n",
      "Epoch 59, Loss: 0.5436848402023315\n",
      "Epoch 60, Loss: 0.5427367687225342\n",
      "Epoch 61, Loss: 0.5419790148735046\n",
      "Epoch 62, Loss: 0.542132556438446\n",
      "Epoch 63, Loss: 0.5419172644615173\n",
      "Epoch 64, Loss: 0.5413359999656677\n",
      "Epoch 65, Loss: 0.5412560105323792\n",
      "Epoch 66, Loss: 0.5410618782043457\n",
      "Epoch 67, Loss: 0.5404219627380371\n",
      "Epoch 68, Loss: 0.5401862263679504\n",
      "Epoch 69, Loss: 0.5402109026908875\n",
      "Epoch 70, Loss: 0.5398378968238831\n",
      "Epoch 71, Loss: 0.5394594669342041\n",
      "Epoch 72, Loss: 0.539328396320343\n",
      "Epoch 73, Loss: 0.5390140414237976\n",
      "Epoch 74, Loss: 0.5386747717857361\n",
      "Epoch 75, Loss: 0.5385954976081848\n",
      "Epoch 76, Loss: 0.5384016633033752\n",
      "Epoch 77, Loss: 0.538040041923523\n",
      "Epoch 78, Loss: 0.5378392338752747\n",
      "Epoch 79, Loss: 0.53765869140625\n",
      "Epoch 80, Loss: 0.5373789668083191\n",
      "Epoch 81, Loss: 0.5372050404548645\n",
      "Epoch 82, Loss: 0.5370457768440247\n",
      "Epoch 83, Loss: 0.5367681980133057\n",
      "Epoch 84, Loss: 0.5365533828735352\n",
      "Epoch 85, Loss: 0.5364031791687012\n",
      "Epoch 86, Loss: 0.5361818671226501\n",
      "Epoch 87, Loss: 0.5359817743301392\n",
      "Epoch 88, Loss: 0.5358176827430725\n",
      "Epoch 89, Loss: 0.5355966091156006\n",
      "Epoch 90, Loss: 0.5353987216949463\n",
      "Epoch 91, Loss: 0.5352491140365601\n",
      "Epoch 92, Loss: 0.5350580215454102\n",
      "Epoch 93, Loss: 0.53486567735672\n",
      "Epoch 94, Loss: 0.5347025394439697\n",
      "Epoch 95, Loss: 0.5345156192779541\n",
      "Epoch 96, Loss: 0.5343378186225891\n",
      "Epoch 97, Loss: 0.5341861844062805\n",
      "Epoch 98, Loss: 0.5340098142623901\n",
      "Epoch 99, Loss: 0.5338332653045654\n",
      "Epoch 100, Loss: 0.5336773991584778\n",
      "Epoch 101, Loss: 0.533510148525238\n",
      "Epoch 102, Loss: 0.5333477854728699\n",
      "Epoch 103, Loss: 0.5331971049308777\n",
      "Epoch 104, Loss: 0.5330325961112976\n",
      "Epoch 105, Loss: 0.5328726172447205\n",
      "Epoch 106, Loss: 0.5327248573303223\n",
      "Epoch 107, Loss: 0.5325700044631958\n",
      "Epoch 108, Loss: 0.5324190258979797\n",
      "Epoch 109, Loss: 0.5322728157043457\n",
      "Epoch 110, Loss: 0.5321202278137207\n",
      "Epoch 111, Loss: 0.5319743156433105\n",
      "Epoch 112, Loss: 0.5318331718444824\n",
      "Epoch 113, Loss: 0.5316874384880066\n",
      "Epoch 114, Loss: 0.5315457582473755\n",
      "Epoch 115, Loss: 0.531406044960022\n",
      "Epoch 116, Loss: 0.53126460313797\n",
      "Epoch 117, Loss: 0.5311286449432373\n",
      "Epoch 118, Loss: 0.5309931039810181\n",
      "Epoch 119, Loss: 0.5308561325073242\n",
      "Epoch 120, Loss: 0.5307231545448303\n",
      "Epoch 121, Loss: 0.5305905342102051\n",
      "Epoch 122, Loss: 0.5304586291313171\n",
      "Epoch 123, Loss: 0.5303297638893127\n",
      "Epoch 124, Loss: 0.5302001237869263\n",
      "Epoch 125, Loss: 0.5300718545913696\n",
      "Epoch 126, Loss: 0.5299460291862488\n",
      "Epoch 127, Loss: 0.5298202633857727\n",
      "Epoch 128, Loss: 0.5296961069107056\n",
      "Epoch 129, Loss: 0.5295733213424683\n",
      "Epoch 130, Loss: 0.5294504165649414\n",
      "Epoch 131, Loss: 0.5293297171592712\n",
      "Epoch 132, Loss: 0.5292099714279175\n",
      "Epoch 133, Loss: 0.5290907025337219\n",
      "Epoch 134, Loss: 0.5289730429649353\n",
      "Epoch 135, Loss: 0.5288559198379517\n",
      "Epoch 136, Loss: 0.5287399888038635\n",
      "Epoch 137, Loss: 0.5286253690719604\n",
      "Epoch 138, Loss: 0.528511106967926\n",
      "Epoch 139, Loss: 0.5283980369567871\n",
      "Epoch 140, Loss: 0.5282860398292542\n",
      "Epoch 141, Loss: 0.5281746983528137\n",
      "Epoch 142, Loss: 0.5280646681785583\n",
      "Epoch 143, Loss: 0.5279552340507507\n",
      "Epoch 144, Loss: 0.5278465747833252\n",
      "Epoch 145, Loss: 0.5277391076087952\n",
      "Epoch 146, Loss: 0.5276322364807129\n",
      "Epoch 147, Loss: 0.5275264382362366\n",
      "Epoch 148, Loss: 0.5274212956428528\n",
      "Epoch 149, Loss: 0.5273169279098511\n",
      "Epoch 150, Loss: 0.5272135138511658\n",
      "Epoch 151, Loss: 0.5271108150482178\n",
      "Epoch 152, Loss: 0.5270088911056519\n",
      "Epoch 153, Loss: 0.5269078612327576\n",
      "Epoch 154, Loss: 0.5268074870109558\n",
      "Epoch 155, Loss: 0.5267078876495361\n",
      "Epoch 156, Loss: 0.5266090631484985\n",
      "Epoch 157, Loss: 0.526511013507843\n",
      "Epoch 158, Loss: 0.5264137387275696\n",
      "Epoch 159, Loss: 0.5263170003890991\n",
      "Epoch 160, Loss: 0.5262210369110107\n",
      "Epoch 161, Loss: 0.5261259078979492\n",
      "Epoch 162, Loss: 0.5260313749313354\n",
      "Epoch 163, Loss: 0.5259374976158142\n",
      "Epoch 164, Loss: 0.5258442759513855\n",
      "Epoch 165, Loss: 0.5257517695426941\n",
      "Epoch 166, Loss: 0.5256599187850952\n",
      "Epoch 167, Loss: 0.5255688428878784\n",
      "Epoch 168, Loss: 0.525478184223175\n",
      "Epoch 169, Loss: 0.5253883004188538\n",
      "Epoch 170, Loss: 0.5252990126609802\n",
      "Epoch 171, Loss: 0.5252103805541992\n",
      "Epoch 172, Loss: 0.5251222252845764\n",
      "Epoch 173, Loss: 0.5250348448753357\n",
      "Epoch 174, Loss: 0.5249479413032532\n",
      "Epoch 175, Loss: 0.524861752986908\n",
      "Epoch 176, Loss: 0.5247761607170105\n",
      "Epoch 177, Loss: 0.5246910452842712\n",
      "Epoch 178, Loss: 0.524606466293335\n",
      "Epoch 179, Loss: 0.524522602558136\n",
      "Epoch 180, Loss: 0.5244391560554504\n",
      "Epoch 181, Loss: 0.5243563055992126\n",
      "Epoch 182, Loss: 0.5242740511894226\n",
      "Epoch 183, Loss: 0.5241923928260803\n",
      "Epoch 184, Loss: 0.5241110920906067\n",
      "Epoch 185, Loss: 0.5240304470062256\n",
      "Epoch 186, Loss: 0.5239503383636475\n",
      "Epoch 187, Loss: 0.5238707065582275\n",
      "Epoch 188, Loss: 0.5237915515899658\n",
      "Epoch 189, Loss: 0.5237129330635071\n",
      "Epoch 190, Loss: 0.5236348509788513\n",
      "Epoch 191, Loss: 0.5235572457313538\n",
      "Epoch 192, Loss: 0.5234801173210144\n",
      "Epoch 193, Loss: 0.523403525352478\n",
      "Epoch 194, Loss: 0.5233272910118103\n",
      "Epoch 195, Loss: 0.5232516527175903\n",
      "Epoch 196, Loss: 0.5231765508651733\n",
      "Epoch 197, Loss: 0.5231018662452698\n",
      "Epoch 198, Loss: 0.5230276584625244\n",
      "Epoch 199, Loss: 0.5229538083076477\n",
      "Epoch 200, Loss: 0.5228804349899292\n",
      "Epoch 201, Loss: 0.5228075981140137\n",
      "Epoch 202, Loss: 0.5227351784706116\n",
      "Epoch 203, Loss: 0.5226630568504333\n",
      "Epoch 204, Loss: 0.5225915908813477\n",
      "Epoch 205, Loss: 0.5225204229354858\n",
      "Epoch 206, Loss: 0.522449791431427\n",
      "Epoch 207, Loss: 0.5223795771598816\n",
      "Epoch 208, Loss: 0.5223097205162048\n",
      "Epoch 209, Loss: 0.5222402811050415\n",
      "Epoch 210, Loss: 0.5221712589263916\n",
      "Epoch 211, Loss: 0.5221026539802551\n",
      "Epoch 212, Loss: 0.5220344662666321\n",
      "Epoch 213, Loss: 0.5219666957855225\n",
      "Epoch 214, Loss: 0.5218993425369263\n",
      "Epoch 215, Loss: 0.5218324065208435\n",
      "Epoch 216, Loss: 0.5217657685279846\n",
      "Epoch 217, Loss: 0.5216995477676392\n",
      "Epoch 218, Loss: 0.5216337442398071\n",
      "Epoch 219, Loss: 0.5215682983398438\n",
      "Epoch 220, Loss: 0.521503210067749\n",
      "Epoch 221, Loss: 0.5214386582374573\n",
      "Epoch 222, Loss: 0.5213742256164551\n",
      "Epoch 223, Loss: 0.5213103294372559\n",
      "Epoch 224, Loss: 0.5212467908859253\n",
      "Epoch 225, Loss: 0.5211836099624634\n",
      "Epoch 226, Loss: 0.5211206674575806\n",
      "Epoch 227, Loss: 0.5210582613945007\n",
      "Epoch 228, Loss: 0.52099609375\n",
      "Epoch 229, Loss: 0.5209344029426575\n",
      "Epoch 230, Loss: 0.520872950553894\n",
      "Epoch 231, Loss: 0.5208117961883545\n",
      "Epoch 232, Loss: 0.5207511186599731\n",
      "Epoch 233, Loss: 0.5206907391548157\n",
      "Epoch 234, Loss: 0.5206306576728821\n",
      "Epoch 235, Loss: 0.5205708742141724\n",
      "Epoch 236, Loss: 0.5205115079879761\n",
      "Epoch 237, Loss: 0.5204524397850037\n",
      "Epoch 238, Loss: 0.5203936696052551\n",
      "Epoch 239, Loss: 0.5203353762626648\n",
      "Epoch 240, Loss: 0.5202772617340088\n",
      "Epoch 241, Loss: 0.5202193856239319\n",
      "Epoch 242, Loss: 0.5201619863510132\n",
      "Epoch 243, Loss: 0.5201049447059631\n",
      "Epoch 244, Loss: 0.5200480818748474\n",
      "Epoch 245, Loss: 0.5199916362762451\n",
      "Epoch 246, Loss: 0.5199353098869324\n",
      "Epoch 247, Loss: 0.5198794007301331\n",
      "Epoch 248, Loss: 0.5198238492012024\n",
      "Epoch 249, Loss: 0.5197685360908508\n",
      "Epoch 250, Loss: 0.5197135210037231\n",
      "Epoch 251, Loss: 0.5196588635444641\n",
      "Epoch 252, Loss: 0.5196045637130737\n",
      "Epoch 253, Loss: 0.5195503830909729\n",
      "Epoch 254, Loss: 0.5194965600967407\n",
      "Epoch 255, Loss: 0.5194430351257324\n",
      "Epoch 256, Loss: 0.519389808177948\n",
      "Epoch 257, Loss: 0.5193368792533875\n",
      "Epoch 258, Loss: 0.5192841291427612\n",
      "Epoch 259, Loss: 0.5192318558692932\n",
      "Epoch 260, Loss: 0.51917964220047\n",
      "Epoch 261, Loss: 0.5191277861595154\n",
      "Epoch 262, Loss: 0.5190761685371399\n",
      "Epoch 263, Loss: 0.5190249085426331\n",
      "Epoch 264, Loss: 0.5189739465713501\n",
      "Epoch 265, Loss: 0.5189231038093567\n",
      "Epoch 266, Loss: 0.5188725590705872\n",
      "Epoch 267, Loss: 0.5188223719596863\n",
      "Epoch 268, Loss: 0.5187724232673645\n",
      "Epoch 269, Loss: 0.518722653388977\n",
      "Epoch 270, Loss: 0.5186731815338135\n",
      "Epoch 271, Loss: 0.5186240077018738\n",
      "Epoch 272, Loss: 0.5185750722885132\n",
      "Epoch 273, Loss: 0.5185264348983765\n",
      "Epoch 274, Loss: 0.5184779763221741\n",
      "Epoch 275, Loss: 0.5184298157691956\n",
      "Epoch 276, Loss: 0.5183818340301514\n",
      "Epoch 277, Loss: 0.5183342099189758\n",
      "Epoch 278, Loss: 0.5182867646217346\n",
      "Epoch 279, Loss: 0.5182394981384277\n",
      "Epoch 280, Loss: 0.5181925296783447\n",
      "Epoch 281, Loss: 0.5181458592414856\n",
      "Epoch 282, Loss: 0.5180993676185608\n",
      "Epoch 283, Loss: 0.5180531144142151\n",
      "Epoch 284, Loss: 0.5180070400238037\n",
      "Epoch 285, Loss: 0.5179612636566162\n",
      "Epoch 286, Loss: 0.5179157257080078\n",
      "Epoch 287, Loss: 0.5178705453872681\n",
      "Epoch 288, Loss: 0.5178253650665283\n",
      "Epoch 289, Loss: 0.5177805423736572\n",
      "Epoch 290, Loss: 0.5177358984947205\n",
      "Epoch 291, Loss: 0.5176914930343628\n",
      "Epoch 292, Loss: 0.5176473259925842\n",
      "Epoch 293, Loss: 0.5176033973693848\n",
      "Epoch 294, Loss: 0.5175597071647644\n",
      "Epoch 295, Loss: 0.5175161361694336\n",
      "Epoch 296, Loss: 0.5174728035926819\n",
      "Epoch 297, Loss: 0.5174298286437988\n",
      "Epoch 298, Loss: 0.5173869132995605\n",
      "Epoch 299, Loss: 0.5173442363739014\n",
      "Epoch 300, Loss: 0.5173017978668213\n",
      "Accuracy:  0.534\n",
      "Precision:  0.5570944947473065\n",
      "Recall:  0.534\n",
      "AUROC:  0.5339999999999999\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import AdamW\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_score, recall_score, roc_auc_score\n",
    "\n",
    "# Load the sentence transformer model\n",
    "model = SentenceTransformer('bert-base-nli-mean-tokens')\n",
    "\n",
    "# Assume we have some data\n",
    "# texts = ['This is a good day!', 'I feel very sad', 'I am not happy about this', 'I am thrilled']\n",
    "# labels = [1, 0, 0, 1]  # 1: Positive sentiment, 0: Negative sentiment\n",
    "X_train = df_image_train['text']\n",
    "y_train = df_image_train['label']\n",
    "\n",
    "X_val = df_image_val['text']\n",
    "y_val = df_image_val['label']\n",
    "\n",
    "# X_test = df_image_test['text']\n",
    "# y_test = df_image_test['label']\n",
    "\n",
    "# # Split into training and testing sets\n",
    "# train_texts, test_texts, train_labels, test_labels = train_test_split(texts, labels, test_size=0.2)\n",
    "\n",
    "# Convert the texts to embeddings\n",
    "train_embeddings = model.encode(X_train)\n",
    "test_embeddings = model.encode(X_val)\n",
    "\n",
    "# Convert everything into torch tensors\n",
    "train_embeddings = torch.tensor(train_embeddings)\n",
    "train_labels = torch.tensor(y_train)\n",
    "\n",
    "test_embeddings = torch.tensor(test_embeddings)\n",
    "test_labels = torch.tensor(y_val)\n",
    "\n",
    "# A simple linear classifier on top of SBERT's embeddings\n",
    "classifier = nn.Linear(train_embeddings.size(1), 2)\n",
    "\n",
    "# Loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Optimizer\n",
    "optimizer = AdamW(classifier.parameters(), lr=1e-2)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(300):  # for simplicity, we train for 10 epochs\n",
    "    classifier.train()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Forward pass\n",
    "    outputs = classifier(train_embeddings)\n",
    "    loss = criterion(outputs, train_labels)\n",
    "\n",
    "    # Backward pass\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    print(f'Epoch {epoch + 1}, Loss: {loss.item()}')\n",
    "\n",
    "# Test the classifier\n",
    "classifier.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = classifier(test_embeddings)\n",
    "    _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "# Compute precision, recall, and AUROC\n",
    "precision = precision_score(test_labels, predicted, average='weighted')\n",
    "recall = recall_score(test_labels, predicted, average='weighted')\n",
    "roc_auc = roc_auc_score(test_labels, predicted)\n",
    "\n",
    "print('Accuracy: ', (predicted == test_labels).sum().item() / test_labels.size(0))\n",
    "print('Precision: ', precision)\n",
    "print('Recall: ', recall)\n",
    "print('AUROC: ', roc_auc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
