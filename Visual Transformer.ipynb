{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\n\n# f = pd.read_json(file_path, lines=True)\ndf_image_train = pd.read_json(\"/kaggle/input/facebook-hateful-meme-dataset/data/train.jsonl\", lines=True)\ndf_image_val = pd.read_json(\"/kaggle/input/facebook-hateful-meme-dataset/data/dev.jsonl\", lines=True)\ndf_image_test = pd.read_json(\"/kaggle/input/facebook-hateful-meme-dataset/data/test.jsonl\", lines=True)\ndf_image_train.head()","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-06-16T02:43:57.521474Z","iopub.execute_input":"2023-06-16T02:43:57.521834Z","iopub.status.idle":"2023-06-16T02:43:57.656934Z","shell.execute_reply.started":"2023-06-16T02:43:57.521805Z","shell.execute_reply":"2023-06-16T02:43:57.656063Z"},"trusted":true},"execution_count":1,"outputs":[{"execution_count":1,"output_type":"execute_result","data":{"text/plain":"      id            img  label  \\\n0  42953  img/42953.png      0   \n1  23058  img/23058.png      0   \n2  13894  img/13894.png      0   \n3  37408  img/37408.png      0   \n4  82403  img/82403.png      0   \n\n                                                text  \n0   its their character not their color that matters  \n1  don't be afraid to love again everyone is not ...  \n2                           putting bows on your pet  \n3  i love everything and everybody! except for sq...  \n4  everybody loves chocolate chip cookies, even h...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>img</th>\n      <th>label</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>42953</td>\n      <td>img/42953.png</td>\n      <td>0</td>\n      <td>its their character not their color that matters</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>23058</td>\n      <td>img/23058.png</td>\n      <td>0</td>\n      <td>don't be afraid to love again everyone is not ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>13894</td>\n      <td>img/13894.png</td>\n      <td>0</td>\n      <td>putting bows on your pet</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>37408</td>\n      <td>img/37408.png</td>\n      <td>0</td>\n      <td>i love everything and everybody! except for sq...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>82403</td>\n      <td>img/82403.png</td>\n      <td>0</td>\n      <td>everybody loves chocolate chip cookies, even h...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# import os\n# import pandas as pd\n# import torch\n# import torchvision.transforms as T\n# from torch import nn, optim\n# from torch.utils.data import Dataset, DataLoader\n# from PIL import Image\n# from transformers import AutoFeatureExtractor, AutoModel\n\n# # Read JSON files\n# df_image_train = pd.read_json(\"/kaggle/input/facebook-hateful-meme-dataset/data/train.jsonl\", lines=True)\n# df_image_val = pd.read_json(\"/kaggle/input/facebook-hateful-meme-dataset/data/dev.jsonl\",lines = True)\n\n# # Get image paths\n# def load_image_paths(df):\n#     image_paths = [os.path.join(\"/kaggle/input/facebook-hateful-meme-dataset/data\", img_path) for img_path in df['img']]\n#     return image_paths\n\n# # Prepare data\n# X_train_images = load_image_paths(df_image_train)\n# y_train = df_image_train['label']\n\n# X_val_images = load_image_paths(df_image_val)\n# y_val = df_image_val['label']\n\n# # Dataset\n# class ImageDataset(Dataset):\n#     def __init__(self, image_paths, labels, transforms=None):\n#         self.image_paths = image_paths\n#         self.labels = labels\n#         self.transforms = transforms\n\n#     def __len__(self):\n#         return len(self.image_paths)\n\n#     def __getitem__(self, idx):\n#         image_path = self.image_paths[idx]\n#         image = Image.open(image_path).convert('RGB')\n#         if self.transforms:\n#             image = self.transforms(image)\n#         label = self.labels[idx]\n#         return image, label\n\n# # Define the transformations\n# transform = T.Compose([\n#     T.Resize((224, 224)),  # Resize to the size expected by DINO\n#     T.ToTensor(),\n# ])\n\n# # Create the datasets\n# train_dataset = ImageDataset(X_train_images, y_train, transforms=transform)\n\n# # Create the dataloaders\n# train_dataloader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n\n# # Create the datasets\n# val_dataset = ImageDataset(X_val_images, y_train, transforms=transform)\n\n# # Create the dataloaders\n# val_dataloader = DataLoader(val_dataset, batch_size=16, shuffle=True)\n\n# # Load pretrained models\n# extractor = AutoFeatureExtractor.from_pretrained(\"facebook/dino-vits8\")\n# model = AutoModel.from_pretrained(\"facebook/dino-vits8\")\n\n# # Add a classification head to the model\n# num_classes = 2\n# model.classifier = nn.Linear(model.config.hidden_size, num_classes)\n\n# # Set up loss function and optimizer\n# criterion = nn.CrossEntropyLoss()\n# optimizer = optim.Adam(model.parameters(), lr=0.00001)\n\n# # Move model to GPU if available\n# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n# model = model.to(device)\n\n# # Training loop\n# num_epochs = 20\n# model.train()\n# for epoch in range(num_epochs):\n#     for images, labels in train_dataloader:\n#         # Move inputs and targets to the same device as the model\n#         images = images.to(device)\n#         labels = labels.to(device)\n\n#         # Forward pass\n#         outputs = model(images)\n#         logits = model.classifier(outputs.pooler_output)\n\n#         # Compute the loss\n#         loss = criterion(logits, labels)\n\n#         # Backward pass and optimization\n#         loss.backward()\n#         optimizer.step()\n#         optimizer.zero_grad()\n    \n#     print(f\"Epoch: {epoch}, Loss: {loss.item()}\")\n    \n#     # Evaluation after each epoch\n#     model.eval()  # Set the model to evaluation mode\n#     with torch.no_grad():  # Do not calculate gradients (saves memory and computation)\n#         correct = 0\n#         total = 0\n#         for images, labels in val_dataloader:\n#             # Move inputs and targets to the same device as the model\n#             images = images.to(device)\n#             labels = labels.to(device)\n\n#             # Forward pass\n#             outputs = model(images)\n#             logits = model.classifier(outputs.pooler_output)\n\n#             # Compute the loss\n#             loss = criterion(logits, labels)\n\n#             # Compute accuracy\n#             _, predicted = torch.max(logits, 1)\n#             total += labels.size(0)\n#             correct += (predicted == labels).sum().item()\n\n#         print(f\"Validation Loss: {loss.item()}\")\n#         print(f\"Validation Accuracy: {correct / total}\")\n        \n#         if (epoch + 1) % 4 == 0:\n#             torch.save(model.state_dict(), f\"vit_{epoch+1}.pth\")\n        \n","metadata":{"execution":{"iopub.status.busy":"2023-06-16T01:39:32.861164Z","iopub.execute_input":"2023-06-16T01:39:32.861701Z","iopub.status.idle":"2023-06-16T01:54:43.869127Z","shell.execute_reply.started":"2023-06-16T01:39:32.861666Z","shell.execute_reply":"2023-06-16T01:54:43.867766Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport pandas as pd\nimport torch\nimport torchvision.transforms as T\nfrom torch import nn, optim\nfrom torch.utils.data import Dataset, DataLoader\nfrom PIL import Image\nfrom transformers import AutoFeatureExtractor, AutoModel\nfrom sklearn.metrics import precision_score, recall_score, roc_auc_score, accuracy_score\n\n# Read JSON files\ndf_image_train = pd.read_json(\"/kaggle/input/facebook-hateful-meme-dataset/data/train.jsonl\", lines=True)\ndf_image_val = pd.read_json(\"/kaggle/input/facebook-hateful-meme-dataset/data/dev.jsonl\",lines = True)\n\n# Get image paths\ndef load_image_paths(df):\n    image_paths = [os.path.join(\"/kaggle/input/facebook-hateful-meme-dataset/data\", img_path) for img_path in df['img']]\n    return image_paths\n\n# Prepare data\nX_train_images = load_image_paths(df_image_train)\ny_train = df_image_train['label']\n\nX_val_images = load_image_paths(df_image_val)\ny_val = df_image_val['label']\n\n# Dataset\nclass ImageDataset(Dataset):\n    def __init__(self, image_paths, labels, transforms=None):\n        self.image_paths = image_paths\n        self.labels = labels\n        self.transforms = transforms\n\n    def __len__(self):\n        return len(self.image_paths)\n\n    def __getitem__(self, idx):\n        image_path = self.image_paths[idx]\n        image = Image.open(image_path).convert('RGB')\n        if self.transforms:\n            image = self.transforms(image)\n        label = self.labels[idx]\n        return image, label\n\n# Define the transformations\ntransform = T.Compose([\n    T.Resize((224, 224)),  # Resize to the size expected by DINO\n    T.ToTensor(),\n])\n\n# Create the datasets\ntrain_dataset = ImageDataset(X_train_images, y_train, transforms=transform)\n\n# Create the dataloaders\ntrain_dataloader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n\n# Create the datasets\nval_dataset = ImageDataset(X_val_images, y_train, transforms=transform)\n\n# Create the dataloaders\nval_dataloader = DataLoader(val_dataset, batch_size=16, shuffle=True)\n\n# Load pretrained models\nextractor = AutoFeatureExtractor.from_pretrained(\"facebook/dino-vits8\")\nmodel = AutoModel.from_pretrained(\"facebook/dino-vits8\")\n\n# Add a classification head to the model\nnum_classes = 2\nmodel.classifier = nn.Linear(model.config.hidden_size, num_classes)\n\n# Set up loss function and optimizer\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=0.00001)\n\n# Move model to GPU if available\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nmodel = model.to(device)\n\n# Training loop\nnum_epochs = 20\nmodel.train()\n\nfor epoch in range(num_epochs):\n    for images, labels in train_dataloader:\n        images = images.to(device)\n        labels = labels.to(device)\n\n        outputs = model(images)\n        logits = model.classifier(outputs.pooler_output)\n\n        loss = criterion(logits, labels)\n\n        loss.backward()\n        optimizer.step()\n        optimizer.zero_grad()\n    \n    print(f\"Epoch: {epoch}, Loss: {loss.item()}\")\n    \n    model.eval()  # Set the model to evaluation mode\n    with torch.no_grad():  # Do not calculate gradients (saves memory and computation)\n        all_labels = []\n        all_predictions = []\n\n        for images, labels in val_dataloader:\n            images = images.to(device)\n            labels = labels.to(device)\n\n            outputs = model(images)\n            logits = model.classifier(outputs.pooler_output)\n\n            _, predicted = torch.max(logits, 1)\n            all_labels.extend(labels.cpu().numpy())\n            all_predictions.extend(predicted.cpu().numpy())\n\n        precision = precision_score(all_labels, all_predictions, average='macro')\n        recall = recall_score(all_labels, all_predictions, average='macro')\n        accuracy = accuracy_score(all_labels, all_predictions)\n\n        print(f\"Validation Precision: {precision}\")\n        print(f\"Validation Recall: {recall}\")\n        print(f\"Validation Accuracy: {accuracy}\")\n        \n        if (epoch + 1) % 4 == 0:\n            torch.save(model.state_dict(), f\"vit_final_{epoch+1}.pth\")\n","metadata":{"execution":{"iopub.status.busy":"2023-06-16T02:44:05.727230Z","iopub.execute_input":"2023-06-16T02:44:05.727654Z","iopub.status.idle":"2023-06-16T04:08:52.505419Z","shell.execute_reply.started":"2023-06-16T02:44:05.727623Z","shell.execute_reply":"2023-06-16T04:08:52.503507Z"},"trusted":true},"execution_count":2,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading (…)rocessor_config.json:   0%|          | 0.00/244 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b579be57a1874fb0809a878fdde7cf57"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n  warnings.warn(f\"file system plugins are not loaded: {e}\")\n/opt/conda/lib/python3.10/site-packages/transformers/models/vit/feature_extraction_vit.py:28: FutureWarning: The class ViTFeatureExtractor is deprecated and will be removed in version 5 of Transformers. Please use ViTImageProcessor instead.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading (…)lve/main/config.json:   0%|          | 0.00/452 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"11704528f7cc47f494888a1237106f2f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading pytorch_model.bin:   0%|          | 0.00/86.8M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f203ad52edff4733aa3c5272c0522cf1"}},"metadata":{}},{"name":"stderr","text":"Some weights of ViTModel were not initialized from the model checkpoint at facebook/dino-vits8 and are newly initialized: ['pooler.dense.weight', 'pooler.dense.bias']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 0, Loss: 0.7275950908660889\nValidation Precision: 0.5081126687435099\nValidation Recall: 0.5053333333333333\nValidation Accuracy: 0.682\nEpoch: 1, Loss: 0.5587728023529053\nValidation Precision: 0.5065968630596778\nValidation Recall: 0.5066666666666666\nValidation Accuracy: 0.628\nEpoch: 2, Loss: 0.6088539958000183\nValidation Precision: 0.5328947368421053\nValidation Recall: 0.532\nValidation Accuracy: 0.654\nEpoch: 3, Loss: 0.2793712615966797\nValidation Precision: 0.5146775632896529\nValidation Recall: 0.5066666666666667\nValidation Accuracy: 0.708\nEpoch: 4, Loss: 0.13934367895126343\nValidation Precision: 0.5165762507534659\nValidation Recall: 0.5146666666666667\nValidation Accuracy: 0.656\nEpoch: 5, Loss: 0.16861902177333832\nValidation Precision: 0.49588382507903056\nValidation Recall: 0.4946666666666667\nValidation Accuracy: 0.538\nEpoch: 6, Loss: 0.4310924708843231\nValidation Precision: 0.5077962577962578\nValidation Recall: 0.508\nValidation Accuracy: 0.626\nEpoch: 7, Loss: 0.0006762255216017365\nValidation Precision: 0.5081221572449642\nValidation Recall: 0.5066666666666667\nValidation Accuracy: 0.66\nEpoch: 8, Loss: 0.0002564936876296997\nValidation Precision: 0.4894674755645433\nValidation Recall: 0.492\nValidation Accuracy: 0.658\nEpoch: 9, Loss: 0.03248279541730881\nValidation Precision: 0.5092373632870234\nValidation Recall: 0.508\nValidation Accuracy: 0.654\nEpoch: 10, Loss: 0.011140908114612103\nValidation Precision: 0.5014474628870516\nValidation Recall: 0.5013333333333333\nValidation Accuracy: 0.64\nEpoch: 11, Loss: 0.007883112877607346\nValidation Precision: 0.5046586165772212\nValidation Recall: 0.5053333333333333\nValidation Accuracy: 0.598\nEpoch: 12, Loss: 0.024254925549030304\nValidation Precision: 0.5285561985988425\nValidation Recall: 0.524\nValidation Accuracy: 0.67\nEpoch: 13, Loss: 0.00023892565513961017\nValidation Precision: 0.5294672324375295\nValidation Recall: 0.5253333333333333\nValidation Accuracy: 0.668\nEpoch: 14, Loss: 0.2045208364725113\nValidation Precision: 0.5061213296507414\nValidation Recall: 0.5066666666666667\nValidation Accuracy: 0.612\nEpoch: 15, Loss: 0.0011121374554932117\nValidation Precision: 0.5119047619047619\nValidation Recall: 0.5133333333333333\nValidation Accuracy: 0.61\nEpoch: 16, Loss: 0.7997291684150696\nValidation Precision: 0.5163766900744157\nValidation Recall: 0.5133333333333333\nValidation Accuracy: 0.666\nEpoch: 17, Loss: 0.0010543863754719496\nValidation Precision: 0.4905652239546269\nValidation Recall: 0.49066666666666664\nValidation Accuracy: 0.62\nEpoch: 18, Loss: 0.002138041891157627\nValidation Precision: 0.49692087890432557\nValidation Recall: 0.4973333333333333\nValidation Accuracy: 0.646\nEpoch: 19, Loss: 0.000967741128988564\nValidation Precision: 0.5201616728970189\nValidation Recall: 0.5226666666666667\nValidation Accuracy: 0.616\n","output_type":"stream"}]},{"cell_type":"code","source":"# Path of the saved model\nmodel_path = \"vit_final_20.pth\"  # modify this to your actual path\n\n# Initialize the same model architecture\nmodel = AutoModel.from_pretrained(\"facebook/dino-vits8\")\nmodel.classifier = nn.Linear(model.config.hidden_size, num_classes)\nmodel = model.to(device)\n\n# Load the saved model parameters\nmodel.load_state_dict(torch.load(model_path))\n\ndf_image_test = pd.read_json(\"/kaggle/input/dev-seen-memes/dev_seen.jsonl\", lines=True)\nX_test_images = load_image_paths(df_image_test)\ny_test = df_image_test['label']\n\n# Create the test dataset and dataloader, assuming that you have already loaded the test data\n# into X_test_images and y_test\ntest_dataset = ImageDataset(X_test_images, y_test, transforms=transform)\ntest_dataloader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n\n# Testing loop\nmodel.eval()  # Set the model to evaluation mode\nwith torch.no_grad():  # Do not calculate gradients (saves memory and computation)\n    all_labels = []\n    all_predictions = []\n\n    for images, labels in test_dataloader:\n        images = images.to(device)\n        labels = labels.to(device)\n\n        outputs = model(images)\n        logits = model.classifier(outputs.pooler_output)\n\n        _, predicted = torch.max(logits, 1)\n        all_labels.extend(labels.cpu().numpy())\n        all_predictions.extend(predicted.cpu().numpy())\n\n    precision = precision_score(all_labels, all_predictions, average='macro')\n    recall = recall_score(all_labels, all_predictions, average='macro')\n    accuracy = accuracy_score(all_labels, all_predictions)\n\n    print(f\"Test Precision: {precision}\")\n    print(f\"Test Recall: {recall}\")\n    print(f\"Test Accuracy: {accuracy}\")","metadata":{"execution":{"iopub.status.busy":"2023-06-16T04:56:09.898015Z","iopub.execute_input":"2023-06-16T04:56:09.898388Z","iopub.status.idle":"2023-06-16T04:56:23.865347Z","shell.execute_reply.started":"2023-06-16T04:56:09.898358Z","shell.execute_reply":"2023-06-16T04:56:23.864384Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stderr","text":"Some weights of ViTModel were not initialized from the model checkpoint at facebook/dino-vits8 and are newly initialized: ['pooler.dense.weight', 'pooler.dense.bias']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"Test Precision: 0.5209017248904153\nTest Recall: 0.517626538221504\nTest Accuracy: 0.52\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}